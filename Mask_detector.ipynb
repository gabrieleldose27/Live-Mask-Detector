{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is transfer learning\n",
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (300, 300, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(r'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')#loading the weight\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False  #Making the layer not to train again\n",
    "  \n",
    "pre_trained_model.summary()\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('mixed7')  #loading layer required\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (2, activation='softmax')(x)           \n",
    "\n",
    "#the trained layer has 2048 classes but we are reducing it to 2 classes(mask and non mask)\n",
    "model = Model( pre_trained_model.input, x) \n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nmask.jpg', 'nmask1.jpg', 'nmask10.jpg', 'nmask11.jpg', 'nmask12.jpg', 'nmask13.jpg', 'nmask14.jpg', 'nmask15.jpg', 'nmask16.jpg', 'nmask17.jpg']\n",
      "['mask.jpg', 'mask1.jpg', 'mask10.jpg', 'mask11.jpg', 'mask12.jpg', 'mask13.jpg', 'mask14.jpg', 'mask15.jpg', 'mask16.jpg', 'mask17.jpg']\n"
     ]
    }
   ],
   "source": [
    "import cv2,os\n",
    "\n",
    "data_path=r'trainset'#r for reading\n",
    "categories=os.listdir(data_path)\n",
    "labels=[i for i in range(len(categories))]\n",
    "\n",
    "label_dict=dict(zip(categories,labels)) #empty dictionary\n",
    "#labelling it\n",
    "print(label_dict)\n",
    "print(categories)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training nmask images: 100\n",
      "total training mask images: 100\n"
     ]
    }
   ],
   "source": [
    "img_size=300\n",
    "data=[]\n",
    "target=[]\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "    folder_path=os.path.join(data_path,category)\n",
    "    img_names=os.listdir(folder_path)\n",
    "        \n",
    "    for img_name in img_names:\n",
    "        img_path=os.path.join(folder_path,img_name)\n",
    "        img=cv2.imread(img_path)\n",
    "\n",
    "        try:\n",
    "            #gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           \n",
    "            #Coverting the image into gray scale\n",
    "            resized=cv2.resize(img,(img_size,img_size))\n",
    "            \n",
    "            data.append(resized)\n",
    "            target.append(label_dict[category])\n",
    "            #appending the image and the label(categorized) into the list (dataset)\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Exception:',e)\n",
    "            #if any exception rasied, the exception will be printed here. And pass to the next image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data=np.array(data)\n",
    "data=data/255\n",
    "data=np.reshape(data,(data.shape[0],img_size,img_size,3 ))\n",
    "target=np.array(target)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "new_target=np_utils.to_categorical(target)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "data,Label = shuffle(data,new_target, random_state=2)\n",
    "train_data = [data,Label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 5, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 816)               209712    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 817       \n",
      "=================================================================\n",
      "Total params: 344,897\n",
      "Trainable params: 344,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_data[0],train_data[1],epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_clsfr=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#source=cv2.VideoCapture(r\"C:\\Users\\Acer\\Desktop\\face mask detector\\face-mask-detection-keras-master\\test_video.mp4\")\n",
    "source=cv2.VideoCapture(0)\n",
    "#source=cv2.imread(r\"C:\\Users\\Acer\\Desktop\\face mask detector\\face-mask-detection-keras-master\\group_mask2\")\n",
    "\n",
    "source.set(1,320)\n",
    "source.set(2,480)\n",
    "\n",
    "\n",
    "labels_dict={0:'MASK',1:'NO MASK'}\n",
    "color_dict={0:(0,255,0),1:(0,0,255)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n",
      "Found 30 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "\n",
    "    ret,img=source.read()\n",
    "    #gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_clsfr.detectMultiScale(img,1.4,5)  \n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "    \n",
    "        face_img=img[y:y+w,x:x+w]\n",
    "        a=int(y)\n",
    "        b=int(x)\n",
    "        a=a/2\n",
    "        b=b/2\n",
    "        print(a)\n",
    "        resized=cv2.resize(face_img,(300,300))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,300,300,3))\n",
    "        result=model.predict(reshaped)\n",
    "\n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "        cv2.putText(img, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    cv2.imshow('LIVE',img)\n",
    "    key=cv2.waitKey(1)\n",
    "    \n",
    "    if(key==27):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "source.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
